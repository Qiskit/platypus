{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning is the machine learning task of finding and learning patterns and trends in data based on only unlabelled data.\n",
    "\n",
    "![](images/unsupervised/hero.png)\n",
    "\n",
    "There are a number of classical and quantum algorithms for different unsupervised learning tasks such as principal component analysis (PCA), clustering, variational autoencoders (VAE), generative adversarial networks (GAN) and boltzmann machines. In the following page we will focus on GANs. \n",
    "\n",
    "The focus of much recent research in near term quantum unsupervised learning has been on the quantum analogues of GANs and Boltzmann machines which are covered in detail in the linked sections:\n",
    "\n",
    "## Quantum generative adversarial networks\n",
    "\n",
    "![](images/qgan/gan_general_flow.svg)\n",
    "\n",
    "Given an a set of data (either classical or quantum) from the probability distribution $P_\\text{real}$, generative adversarial networks train a generator, $G_\\theta$, and disciminator, $D_\\phi$, simultaneously to create samples from $P_G$ that are indistinguishable from $P_\\text{real}$. The GAN optimization problem is formalized as:\n",
    "\n",
    "$$\\min_G \\max_D \\vec{E}_{x \\sim P_\\text{real}} \\left [ \\log D(x) \\right ] + \\vec{E}_{z \\sim P_G} [\\log ( 1- D(G(z)))] $$\n",
    "\n",
    "$G_\\theta$ and $D_\\phi$ can both be classical or quantum machine learning models.\n",
    "\n",
    "This is covered in the [next page](./quantum-generative-adversarial-networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Boltzmann Machines\n",
    "\n",
    "![](images/qbm/qbm-2.svg)\n",
    "\n",
    "Given data points from a probability distribution the QBM seeks to learn the distribution $P_v$ that resembles $P_v^\\text{data}$. For the parameters $\\vec{w}, \\vec{b}$ the goal is to maximize the log likelihood $L = \\sum_v P_v^\\text{data} \\log P_v $, where $P_v = \\frac{e^{-E_v}}{\\sum_h e^{-E_h}}$ and the energy is represented as the Ising model $E_v = - \\sum_i b_i v_i - \\sum_{i, j} w_{i, j} v_i v_j$.\n",
    "\n",
    "This is covered in the [quantum Boltzmann machines page](./quantum-boltzmann-machines).\n",
    "\n",
    "Both methods are capable of working with classical and quantum data. As before, when working with classical data there are a number of strategies to define the encoding scheme, as outlined in the [data encoding page](./data-encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. Advances in neural information processing systems, 27.](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)\n",
    "\n",
    "2. [Zoufal, C., Lucchi, A., & Woerner, S. (2019). Quantum generative adversarial networks for learning and loading random distributions. npj Quantum Information, 5(1), 1-9.](https://www.nature.com/articles/s41534-019-0223-2)\n",
    "\n",
    "3.  [Amin, M. H., Andriyash, E., Rolfe, J., Kulchytskyy, B., & Melko, R. (2018). Quantum boltzmann machine. Physical Review X, 8(2), 021050.](https://journals.aps.org/prx/abstract/10.1103/PhysRevX.8.021050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
