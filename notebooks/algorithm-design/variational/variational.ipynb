{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "advantage": {
      "text": "Practical demonstration of a quantum computer's ability to solve certain computational problems faster than classical computers.",
      "title": "Quantum Advantage"
     },
     "converge": {
      "text": "Reaching a stable and optimal solution, where further iterations or modifications to the algorithm no longer result in significant improvements or changes to the solution.",
      "title": "Converge"
     }
    }
   },
   "source": [
    "This course covers the specifics of variational algorithms and near-term hybrid quantum-classical algorithms based on the variational theorem of quantum mechanics. These algorithms can leverage the utility provided by today's non-fault-tolerant quantum computers, making them ideal candidates to achieve [quantum advantage](gloss:advantage).\n",
    "\n",
    "Throughout this course, we will explore:\n",
    "\n",
    "- Each step in the variational algorithm design workflow\n",
    "- Trade-offs associated with each step\n",
    "- How to use [Qiskit Runtime primitives](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/primitives.html) to optimize for speed and accuracy\n",
    "\n",
    "While this course is meant to be a starting place for researchers and developers to explore the utility of quantum computers, feel free to explore the theoretical and foundational knowledge around quantum computing in general in the [Basics of Quantum Information and Computation](https://qiskit.org/learn/course/basics-quantum-information/) (also available as [a series of YouTube videos](https://www.youtube.com/playlist?list=PLOFEBzvs-VvqKKMXX4vbi4EB1uaErFMSO))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified hybrid workflow\n",
    "\n",
    "![Variational Flow](images/variational_workflow.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "cost_function": {
      "text": "A mathematical function used to measure the difference between the predicted output of a model or algorithm and the actual output, with the goal of minimizing this difference through optimization.",
      "title": "Cost Function"
     }
    }
   },
   "source": [
    "Variational algorithms include several modular components that can be combined and optimized based on algorithm, software, and hardware advancements. This includes a *cost function* that describes a specific problem with a set of parameters, an *ansatz* to express the search space with these parameters, and an *optimizer* to iteratively explore the search space. During each iteration, the optimizer evaluates the cost function with the current parameters and selects the next iteration's parameters until it [converges](gloss:converge) on an optimal solution. The hybrid nature of this family of algorithms comes from the fact that the cost functions are evaluated using quantum resources and optimized through classical ones.\n",
    "\n",
    "1. **Initialize problem**: Variational algorithms start by initializing the quantum computer in a _default state_ $|0\\rangle$, then transforming it to some desired (non-parametrized) state $|\\rho\\rangle$, which we will call _reference state_. \n",
    "   \n",
    "   This transformation is represented by the application of a unitary reference operator $U_R$ on the default state, such that $U_R|0\\rangle = |\\rho\\rangle$.\n",
    "\n",
    "2. **Prepare ansatz**: To begin iteratively optimizing from the default state $|0\\rangle$ to the target state $|\\psi(\\vec\\theta)\\rangle$, we must define a *variational form* $U_V(\\vec\\theta)$ to represent a collection of parametrized states for our variational algorithm to explore.\n",
    "   \n",
    "   We refer to any particular combination of reference state and variational form as an ansatz, such that: $U_A(\\vec\\theta) := U_V(\\vec\\theta) U_R$. Ansatze will ultimately take the form of parametrized quantum circuits capable of taking the default state $|0\\rangle$ to the target state $|\\psi(\\vec\\theta)\\rangle$.\n",
    "\n",
    "\n",
    "   All in all we will have:\n",
    "\n",
    "   $$\n",
    "   \\begin{aligned}\n",
    "   |0\\rangle \\xrightarrow{U_R} U_R|0\\rangle\n",
    "\n",
    "   & = |\\rho\\rangle \\xrightarrow{U_V(\\vec{\\theta})} U_A(\\vec{\\theta})|0\\rangle \\\\[1mm]\n",
    "\n",
    "   & = U_V(\\vec{\\theta})U_R|0\\rangle \\\\[1mm]\n",
    "\n",
    "   & = U_V(\\vec{\\theta})|\\rho\\rangle \\\\[1mm]\n",
    "\n",
    "   & = |\\psi(\\vec{\\theta})\\rangle \\\\[1mm]\n",
    "\n",
    "   \\end{aligned}\n",
    "   $$\n",
    "\n",
    "3. **Evaluate cost function**: We can encode our problem into a _cost function_ $C(\\vec\\theta)$ as a linear combination of Pauli operators, run on a quantum system. While this can be information about a physical system, such as energy or spin, we can also encode non-physical problems as well. We can leverage Qiskit Runtime primitives to address noise with error suppression and mitigation while evaluating our cost function.\n",
    "   \n",
    "4. **Optimize parameters**: Evaluations are taken to a classical computer, where a classical optimizer analyzes them and chooses the next set of values for the variational parameters. If we have a pre-existing optimal solution, we can set it as an *initial point* $\\vec\\theta_0$ to *bootstrap* our optimization. Using this *initial state* $|\\psi(\\vec\\theta_0)\\rangle$ could help our optimizer find a valid solution faster.\n",
    "\n",
    "5. **Adjust ansatz parameters with results, and re-run**: the  entire process is repeated until the classical optimizer's finalization criteria are met, and an optimal set of parameter values $\\vec\\theta^*$ is returned. The proposed solution state for our problem will then be $|\\psi(\\vec\\theta^*)\\rangle = U_A(\\vec\\theta^*)|0\\rangle$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational theorem\n",
    "\n",
    "A common goal of variational algorithms is to find the quantum state with the lowest or highest eigenvalue of a certain observable. A key insight we'll use is the _variational theorem_ of quantum mechanics. Before going into its full statement, let us explore some of the mathematical intuition behind it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "decomposition": {
      "text": "Process of expressing a matrix as a sum of eigenvalues and eigenvectors, which enables the analysis and manipulation of its properties and behavior.",
      "title": "Spectral Decomposition"
     },
     "eigenstate": {
      "text": "State of a physical system in which a magnitude like energy or momentum has a fixed value.",
      "title": "Eigenstate"
     }
    }
   },
   "source": [
    "### Mathematical intuition for energy and ground states\n",
    "\n",
    "In quantum mechanics, energy comes in the form of a quantum observable usually referred to as the _Hamiltonian_, which we'll denote by $\\hat{\\mathcal{H}}$. Let us consider its [spectral decomposition](gloss:decomposition): \n",
    "\n",
    "$$\n",
    "\\hat{\\mathcal{H}} = \\sum_{k=0}^{N-1} \\lambda_k |\\phi_k\\rangle \\langle \\phi_k|\n",
    "$$\n",
    "\n",
    "where $N$ is the dimensionality of the space of states, $\\lambda_{k}$ is the $k$-th eigenvalue or, physically, the $k$-th energy level, and $|\\phi_k\\rangle$ is the corresponding [eigenstate](gloss:eigenstate): $\\hat{\\mathcal{H}}|\\phi_k\\rangle = \\lambda_k |\\phi_k\\rangle$, the expected energy of a system in the (normalized) state $|\\psi\\rangle$ will be:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle \\psi | \\hat{\\mathcal{H}} | \\psi \\rangle\n",
    "\n",
    "& = \\langle \\psi |\\bigg(\\sum_{k=0}^{N-1} \\lambda_k |\\phi_k\\rangle \\langle \\phi_k|\\bigg) | \\psi \\rangle \\\\[1mm]\n",
    "\n",
    "& = \\sum_{k=0}^{N-1} \\lambda_k \\langle \\psi |\\phi_k\\rangle \\langle \\phi_k| \\psi \\rangle \\\\[1mm]\n",
    "\n",
    "& = \\sum_{k=0}^{N-1} \\lambda_k |\\langle \\psi |\\phi_k\\rangle|^2 \\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If we take into account that $\\lambda_0\\leq \\lambda_k, \\forall k$, we have:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle \\psi | \\hat{\\mathcal{H}} | \\psi \\rangle\n",
    "\n",
    "& = \\sum_{k=0}^{N-1} \\lambda_k |\\langle \\psi |\\phi_k\\rangle|^2 \\\\[1mm]\n",
    "\n",
    "& \\geq  \\sum_{k=0}^{N-1} \\lambda_0 |\\langle \\psi |\\phi_k\\rangle|^2 \\\\[1mm]\n",
    "\n",
    "& = \\lambda_0 \\sum_{k=0}^{N-1} |\\langle \\psi |\\phi_k\\rangle|^2 \\\\[1mm]\n",
    "\n",
    "& = \\lambda_0 \\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Since `{latex} \\{ |\\phi_k\\rangle \\}_{k=0}^{N-1}` is an orthonormal basis, the probability of measuring $|\\phi_{k} \\rangle$ is $p_k = |\\langle \\psi |\\phi_{k} \\rangle |^2$, and the sum of all probabilities is such that $\\sum_{k=0}^{N-1} |\\langle \\psi |\\phi_k\\rangle|^2 = \\sum_{k=0}^{N-1}p_k = 1$. In short, the expected energy of any system is higher than the lowest energy or ground state energy:\n",
    "\n",
    "$$\n",
    "\\langle \\psi | \\hat{\\mathcal{H}} | \\psi \\rangle \\geq \\lambda_0.\n",
    "$$\n",
    "\n",
    "The above argument applies to any valid (normalized) quantum state $|\\psi\\rangle$, so it is perfectly possible to consider parametrized states $|\\psi(\\vec\\theta)\\rangle$ that depend on a parameter vector $\\vec\\theta$. This is where the \"variational\" part comes into play. If we consider a cost function given by $C(\\vec\\theta) := \\langle \\psi(\\vec\\theta)|\\hat{\\mathcal{H}}|\\psi(\\vec\\theta)\\rangle$ and want to minimize it, the minimum will always satisfy:\n",
    "\n",
    "$$\n",
    "\\min_{\\vec\\theta} C(\\vec\\theta) = \n",
    "\\min_{\\vec\\theta} \\langle \\psi(\\vec\\theta)|\\hat{\\mathcal{H}}|\\psi(\\vec\\theta)\\rangle \\geq \\lambda_0.\n",
    "$$\n",
    "\n",
    "The minimum value of $C(\\vec\\theta)$ will be the closest that one can get to $\\lambda_0$ using the parametrized states $|\\psi(\\vec\\theta)\\rangle$, and equality will only be reached if there exists a parameter vector $\\vec\\theta^*$ such that $|\\psi(\\vec\\theta^*)\\rangle = |\\phi_0\\rangle$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "expectation": {
      "text": "Average value of a measurement of a quantum system in a particular state, weighted by the probability of the outcome of the state.",
      "title": "Expectation values"
     }
    }
   },
   "source": [
    "### Variational theorem of Quantum Mechanics \n",
    "\n",
    "If the (normalized) state $|\\psi\\rangle$ of a quantum system depends on a parameter vector $\\vec\\theta$, then the optimal approximation of the ground state (i.e. the eigenstate $|\\phi_0\\rangle$ with the minimum eigenvalue $\\lambda_0$) is the one that minimizes the [expectation value](gloss:expectation) of the Hamiltonian $\\hat{\\mathcal{H}}$:\n",
    "\n",
    "$$\n",
    "\\langle \\hat{\\mathcal{H}} \\rangle(\\vec\\theta) := \n",
    "\\langle \\psi(\\vec\\theta) |\\hat{\\mathcal{H}}| \\psi(\\vec\\theta) \\rangle \\geq \n",
    "\\lambda_0\n",
    "$$\n",
    "\n",
    "The reason why the variational theorem is stated in terms of energy minima is that it includes a number of mathematical assumptions:\n",
    "\n",
    "- For physical reasons, a finite lower bound to the energy $E \\geq \\lambda_0 > -\\infty$ needs to exist, even for $N\\rightarrow\\infty$.\n",
    "- Upper bounds do not generally exist.\n",
    "\n",
    "However, mathematically speaking, there is nothing special about the Hamiltonian $\\hat{\\mathcal{H}}$ beyond these assumptions, so the theorem can be generalized to other quantum observables and their eigenstates provided they follow the same constraints. Also, note that if finite upper bounds exist, the same mathematical arguments could be made for maximizing eigenvalues by swapping lower bounds for upper bounds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this lesson, you learned the high-level view of variational algorithms. Over the following lessons, we'll explore each step in greater detail, and their associated trade-offs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
