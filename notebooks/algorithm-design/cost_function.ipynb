{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions\n",
    "\n",
    "During this lesson, we'll learn how to evaluate a *cost function*:\n",
    "\n",
    "- First, we'll learn about [Qiskit Runtime primitives](https://qiskit.org/documentation/apidoc/primitives.html)\n",
    "- Define a *cost function* $C(\\vec\\theta)$. This is a problem-specific function that defines the problem's goal for the optimizer to minimize (or maximize)\n",
    "- Defining a measurement strategy with the Qiskit Runtime primitives. We'll be addressing noise while also optimizing speed vs accuracy\n",
    "\n",
    "![Cost Function Workflow](images/cost_function_workflow.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "primitives": {
      "text": "Basic and fundamental operations or data type. Qiskit has the Sampler and Estimator primitives to serve as building blocks to easily construct complex workloads, like variational algorithms.",
      "title": "Primitives"
     }
    }
   },
   "source": [
    "## Primitives\n",
    "\n",
    "All physical systems, whether classical or quantum, can exist in different states. For example, a car on a road can have a certain mass, position, speed, or acceleration that characterize its state. Similarly, quantum systems can also have different configurations or states, but they differ from classical systems in how we deal with measurements and state evolution. This leads to unique properties such as *superposition* and *entanglement* that are exclusive to quantum mechanics. Just like we can describe a car's state using physical properties like speed or acceleration, we can also describe the state of a quantum system using *observables*, which are mathematical objects.\n",
    "\n",
    "In quantum mechanics, states are represented by normalized complex column vectors, or *kets* ($|\\psi\\rangle$), and observables are hermitian linear operators ($\\hat{H}=\\hat{H}^{\\dagger}$) that act on the kets. An eigenvector ($|\\lambda\\rangle$) of an observable is known as an *eigenstate*. Measuring an observable for one of its eigenstates ($|\\lambda\\rangle$) will give us the corresponding eigenvalue ($\\lambda$) as readout.\n",
    "\n",
    "\n",
    "If you're wondering how to measure a quantum system and what you can measure, Qiskit offers two [primitives](gloss:primitives) that can help:\n",
    "\n",
    "* `Sampler`: Given a quantum state $|\\psi\\rangle$, this primitive obtains the probability of each possible computational basis state.\n",
    "* `Estimator`: Given a quantum observable $\\hat{H}$ and a state $|\\psi\\rangle$, this primitive computes the expected value of $\\hat{H}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sampler primitive\n",
    "\n",
    "The `Sampler` primitive calculates the probability of obtaining each possible state $|k\\rangle$ from the computational basis, given a quantum circuit that prepares the state $|\\psi\\rangle$. It calculates\n",
    "\n",
    "$$\n",
    "p_k = |\\langle k | \\psi \\rangle|^2 \\quad \\forall k \\in \\mathbb{Z}_2^n \\equiv \\{0,1,\\cdots,2^n-1\\},\n",
    "$$ \n",
    "\n",
    "Where $n$ is the number of qubits, and $k$ the integer representation of any possible output binary string $\\{0,1\\}^n$ (i.e. integers base $2$).\n",
    "\n",
    "\n",
    "[Qiskit Runtime's](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/stubs/qiskit_ibm_runtime.Sampler.html) `Sampler` runs the circuit multiple times on a quantum device, performing measurements on each run, and reconstructing the probability distribution from the recovered bitstrings. The more runs (or *shots*) it performs, the more accurate the results will be, but this requires more time and quantum resources.\n",
    "\n",
    "\n",
    "However, since the number of possible outputs grows exponentially with the number of qubits $n$ (i.e. $2^n$), the number of shots will need to grow exponentially as well in order to capture a _dense_ probability distribution. Therefore, `Sampler` is only efficient for *sparse* probability distributions; where the target state $|\\psi\\rangle$ must be expressible as a linear combination of the computational basis states, with the number of terms growing at most polynomially with the number of qubits: \n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\sum^{\\text{Poly}(n)}_k w_k |k\\rangle.\n",
    "$$\n",
    "\n",
    "\n",
    "The `Sampler` can also be configured to retrieve probabilities from a subsection of the circuit, representing a subset of the total possible states."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "pauli": {
      "text": "Set of matrices commonly used in quantum computing to represent and manipulate quantum states, consisting of the identity matrix and the three Pauli matrices (X, Y, and Z).",
      "title": "Pauli Operators"
     }
    }
   },
   "source": [
    "### The Estimator primitive\n",
    "\n",
    "\n",
    "The `Estimator` primitive calculates the expectation value of an observable $\\hat{H}$ for a quantum state $|\\psi\\rangle$; where the observable probabilities can be expressed as $p_\\lambda = |\\langle\\lambda|\\psi\\rangle|^2$, being $|\\lambda\\rangle$ the eigenstates of the observable $\\hat{H}$. The expectation value is then defined as the average of all possible outcomes $\\lambda$ (i.e. the eigenvalues of the observable) of a measurement of the state $|\\psi\\rangle$, weighted by the corresponding probabilities: \n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi := \\sum_\\lambda p_\\lambda \\lambda = \\langle \\psi | \\hat{H} | \\psi \\rangle\n",
    "$$\n",
    "\n",
    "\n",
    "However, calculating the expectation value of an observable is not always possible, as we often don't know its eigenbasis. [Qiskit Runtime's](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/stubs/qiskit_ibm_runtime.Estimator.html) `Estimator` uses a complex algebraic process to estimate the expectation value on a real quantum device by breaking down the observable into a combination of other observables whose eigenbasis we do know.\n",
    "\n",
    "In simpler terms, `Estimator` breaks down any observable that it doesn't know how to measure into simpler, measurable observables called [Pauli operators](gloss:pauli)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operator can be expressed as a combination of $4^n$ Pauli operators. \n",
    "\n",
    "$$\n",
    "\\hat{P}_k := \n",
    "\\sigma_{k_{n-1}}\\otimes \\cdots \\otimes \\sigma_{k_0} \\quad \n",
    "\\forall k \\in \\mathbb{Z}_4^n \\equiv \\{0,1,\\cdots,4^n-1\\}, \\\\\n",
    "$$ \n",
    "\n",
    "such that \n",
    "\n",
    "$$\n",
    "\\hat{H} = \\sum^{4^n-1}_{k=0} w_k \\hat{P}_k,\n",
    "$$\n",
    "\n",
    "where $n$ is the number of qubits, $k \\equiv k_{n-1} \\cdots k_0$ for $k_l \\in \\mathbb{Z}_4 \\equiv \\{0, 1, 2, 3\\}$ (i.e. integers base $4$), and $(\\sigma_0, \\sigma_1, \\sigma_2, \\sigma_3) := (I, X, Y, Z)$.\n",
    "\n",
    "After performing this decomposition, `Estimator` derives a new circuit $V_k|\\psi\\rangle$ for each observable $\\hat{P}_k$ (i.e. from the original circuit), to effectively *diagonalize* the Pauli observable in the computational basis and measure it. We can easily measure Pauli observables because we know $V_k$ ahead of time, which is not the case generally for other observables.\n",
    "\n",
    "For each $\\hat{P}_{k}$, the `Estimator` runs the corresponding circuit on a quantum device multiple times, measures the output state in the computational basis, and calculates the probability $p_{kj}$ of obtaining each possible output $j$. It then looks for the eigenvalue $\\lambda_{kj}$ of $P_k$ corresponding to each output $j$, multiplies by $w_k$, and adds all the results together to obtain the expected value of the observable $\\hat{H}$ for the given state $|\\psi\\rangle$.\n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi = \n",
    "\\sum_{k=0}^{4^n-1} w_k \\sum_{j=0}^{2^n-1}p_{kj} \\lambda_{kj},\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "sampling": {
      "text": "The process of taking several measurements of one or several things.",
      "title": "Sampling"
     }
    }
   },
   "source": [
    "Since calculating the expectation value of $4^n$ Paulis is impractical (i.e. exponentially growing), `Estimator` can only be efficient when a large amount of $w_k$ are zero (i.e. *sparse* Pauli decomposition instead of *dense*). Formally we say that, for this computation to be *efficiently solvable*, the number of non-zero terms has to grow at most polynomially with the number of qubits $n$: $\\hat{H} = \\sum^{\\text{Poly}(n)}_k w_k \\hat{P}_k.$\n",
    "\n",
    "The reader may notice the implicit assumption that probability [sampling](gloss:sampling) also needs to be efficient as explained for `Sampler`, which means\n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi = \n",
    "\\sum_{k}^{\\text{Poly}(n)} w_k \\sum_{j}^{\\text{Poly}(n)}p_{kj} \\lambda_{kj}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided example to calculate expectation values\n",
    "\n",
    "Let's assume the single-qubit state $|+\\rangle := H|0\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$, and observable \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{H}\n",
    "& = \\begin{pmatrix} \n",
    "-1 & 2 \\\\\n",
    "2 & -1 \\\\\n",
    "\\end{pmatrix}\\\\[1mm]\n",
    "& = 2X - Z\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with the following theoretical expectation value $\\langle\\hat{H}\\rangle_+ = \\langle+|\\hat{H}|+\\rangle = 2.$\n",
    "\n",
    "Since we do not know how to measure this observable, we cannot compute its expectation value directly, and we need to re-express it as $\\langle\\hat{H}\\rangle_+ = 2\\langle X \\rangle_+ - \\langle Z \\rangle_+ $. Which can be shown to evaluate to the same result by virtue of noting that $\\langle+|X|+\\rangle = 1$, and $\\langle+|Z|+\\rangle = 0$.\n",
    "\n",
    "Let see how to compute $\\langle X \\rangle_+$ and $\\langle Z \\rangle_+$ directly. Since $X$ and $Z$ do not commute (i.e. don't share the same eigenbasis), they cannot be measured simultaneously, therefore we need the auxiliary circuits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# The following code will work for any other initial single-qubit state and observable\n",
    "original_circuit = QuantumCircuit(1)\n",
    "original_circuit.h(0)\n",
    "\n",
    "H = SparsePauliOp([\"X\", \"Z\"], [2, -1])\n",
    "\n",
    "aux_circuits = []\n",
    "for pauli in H.paulis:\n",
    "    aux_circ = original_circuit.copy()\n",
    "    aux_circ.barrier()\n",
    "    if str(pauli) == \"X\":\n",
    "        aux_circ.h(0)\n",
    "    elif str(pauli) == \"Y\":\n",
    "        aux_circ.sdg(0)\n",
    "        aux_circ.h(0)\n",
    "    else:\n",
    "        aux_circ.i(0)\n",
    "    aux_circ.measure_all()\n",
    "    aux_circuits.append(aux_circ)\n",
    "\n",
    "\n",
    "print(\"Original circuit:\")\n",
    "display(original_circuit.draw(\"mpl\"))\n",
    "for (circuit, pauli) in zip(aux_circuits, H.paulis):\n",
    "    print(f\"Auxiliary circuit for {str(pauli)}\")\n",
    "    display(circuit.draw(\"mpl\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now carry out the computation manually using `Sampler` and check the results on `Estimator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import Sampler, Estimator\n",
    "from qiskit.circuit.library import IGate, ZGate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## SAMPLER\n",
    "sampler = Sampler()\n",
    "job = sampler.run(aux_circuits)\n",
    "probability_dists = job.result().quasi_dists\n",
    "\n",
    "expvals = []\n",
    "for dist, pauli in zip(probability_dists, H.paulis): \n",
    "    val = 0\n",
    "    if str(pauli) == \"I\":\n",
    "        Lambda = IGate().to_matrix().real\n",
    "    else:\n",
    "        Lambda = ZGate().to_matrix().real\n",
    "    val += Lambda[0][0]*dist.get(0, 0)\n",
    "    val += Lambda[1][1]*dist.get(1, 0)\n",
    "    expvals.append(val)\n",
    "\n",
    "\n",
    "print(\"Sampler results:\")\n",
    "for (pauli, expval) in zip(H.paulis, expvals):\n",
    "    print(f\"  >> Expected value of {str(pauli)}: {expval:.5f}\")\n",
    "\n",
    "total_expval = np.sum(H.coeffs*expvals).real\n",
    "print(f\"  >> Total expected value: {total_expval:.5f}\")\n",
    "\n",
    "\n",
    "## ESTIMATOR\n",
    "observables = [*H.paulis, H]  # Note: run for individual Paulis as well as full observable H\n",
    "\n",
    "estimator = Estimator()\n",
    "job = estimator.run([original_circuit]*len(observables), observables)\n",
    "estimator_expvals = job.result().values\n",
    "\n",
    "print(\"Estimator results:\")\n",
    "for (obs, expval) in zip(observables, estimator_expvals):\n",
    "    if obs is not H:\n",
    "        print(f\"  >> Expected value of {str(obs)}: {expval:.5f}\")\n",
    "    else:\n",
    "        print(f\"  >> Total expected value: {expval:.5f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical rigor (optional)\n",
    "\n",
    "Expressing $|\\psi\\rangle$ with respect to the basis of eigenstates of $\\hat{H}$, $|\\psi\\rangle = \\sum_\\lambda a_\\lambda |\\lambda\\rangle$, it follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle \\psi | \\hat{H} | \\psi \\rangle\n",
    "& = \\bigg(\\sum_{\\lambda'}a^*_{\\lambda'} \\langle \\lambda'|\\bigg) \\hat{H} \n",
    "  \\bigg(\\sum_{\\lambda} a_\\lambda | \\lambda\\rangle\\bigg)\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \n",
    "  \\langle \\lambda'|\\hat{H}| \\lambda\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \\lambda \n",
    "\\langle \\lambda'| \\lambda\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \\lambda \n",
    "\\cdot \\delta_{\\lambda, \\lambda'}\\\\[1mm]\n",
    "\n",
    "& = \\sum_\\lambda |a_\\lambda|^2 \\lambda\\\\[1mm]\n",
    "\n",
    "& = \\sum_\\lambda p_\\lambda \\lambda\\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "hermitian": {
      "text": "A hermitian is a square matrix that is equal to its own conjugate transpose, or a linear operator that is self-adjoint.",
      "title": "Hermitian"
     }
    }
   },
   "source": [
    "Since we do not know the eigenvalues or eigenstates of the target observable $\\hat{H}$, first we need to consider its diagonalization. Given that $\\hat{H}$ is [hermitian](gloss:hermitian), there exists a unitary transformation $V$ such that $\\hat{H}=V^\\dagger \\Lambda V,$ where $\\Lambda$ is the diagonal eigenvalue matrix, so $\\langle j | \\Lambda | k \\rangle = 0$ if $j\\neq k$, and $\\langle j | \\Lambda | j \\rangle = \\lambda_j$.\n",
    "\n",
    "This implies that the expected value can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle\n",
    "& = \\langle\\psi|V^\\dagger \\Lambda V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\langle\\psi|V^\\dagger \\bigg(\\sum_{j=0}^{2^n-1} |j\\rangle \n",
    "\\langle j|\\bigg) \\Lambda \\bigg(\\sum_{k=0}^{2^n-1} |k\\rangle \\langle k|\\bigg) V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1} \\sum_{k=0}^{2^n-1}\\langle\\psi|V^\\dagger |j\\rangle \n",
    "\\langle j| \\Lambda  |k\\rangle \\langle k| V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1}\\langle\\psi|V^\\dagger |j\\rangle \n",
    "\\langle j| \\Lambda  |j\\rangle \\langle j| V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1}|\\langle j| V|\\psi\\rangle|^2 \\lambda_j\\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Given that if a system is in the state $|\\phi\\rangle = V |\\psi\\rangle$ the probability of measuring $| j\\rangle$ is $p_j = |\\langle j|\\phi \\rangle|^2$, the above expected value can be expressed as:\n",
    "\n",
    "$$\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle = \n",
    "\\sum_{j=0}^{2^n-1} p_j \\lambda_j.\n",
    "$$\n",
    "\n",
    "It is very important to note that the probabilities are taken from the state $V |\\psi\\rangle$ instead of $|\\psi\\rangle$. This is why the matrix $V$ is absolutely necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering how to obtain the matrix $V$ and the eigenvalues $\\Lambda$. If you already had the eigenvalues, then there would be no need to use a quantum computer since the goal of variational algorithms is to find these eigenvalues of $\\hat{H}$.\n",
    "\n",
    "Fortunately, there is a way around that: any $2^n \\times 2^n$ matrix can be written as a linear combination of $4^n$ tensor products of $n$ Pauli matrices and identities, all of which are both hermitian and unitary with known $V$ and $\\Lambda$. This is what Runtime's `Estimator` does internally by decomposing any [Operator](https://qiskit.org/documentation/stubs/qiskit.quantum_info.Operator.html) object into a [SparsePauliOp](https://qiskit.org/documentation/stubs/qiskit.quantum_info.SparsePauliOp.html).\n",
    "\n",
    "Here are the Operators that can be used:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c}\n",
    "  \\text{Operator} & \\sigma & V & \\Lambda \\\\[1mm]\n",
    "  \\hline\n",
    "  I & \\sigma_0 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} & V_0 = I & \\Lambda_0 = I = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  X & \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} & V_1 = H =\\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} & \\Lambda_1 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  Y & \\sigma_2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} & V_2 = HS^\\dagger  =\\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\cdot  \\begin{pmatrix} 1 & 0 \\\\ 0 & -i \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -i \\\\ 1 & i \\end{pmatrix}\\quad & \\Lambda_2 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  Z & \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} & V_3 = I & \\Lambda_3 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's rewrite $\\hat{H}$ with respect to the Paulis and identities: \n",
    "\n",
    "$$\n",
    "\\hat{H} = \n",
    "\\sum_{k_{n-1}=0}^3...\n",
    "\\sum_{k_0=0}^3 w_{k_{n-1}...k_0} \n",
    "\\sigma_{k_{n-1}}\\otimes ... \\otimes \\sigma_{k_0} = \\sum_{k=0}^{4^n-1} w_k \\hat{P}_k,\n",
    "$$\n",
    "\n",
    "where $k = \\sum_{l=0}^{n-1} 4^l k_l \\equiv k_{n-1}...k_0$ for $k_{n-1},...,k_0\\in \\{0,1,2,3\\}$ (i.e. base $4$), and $\\hat{P}_{k} := \\sigma_{k_{n-1}}\\otimes ... \\otimes \\sigma_{k_0}$. Then,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle\n",
    "& = \\sum_{k=0}^{4^n-1} w_k \n",
    "\\sum_{j=0}^{2^n-1}|\\langle j| V_k|\\psi\\rangle|^2 \\langle j| \\Lambda_k |j\\rangle \\\\[1mm]\n",
    "\n",
    "& = \\sum_{k=0}^{4^n-1} w_k \\sum_{j=0}^{2^n-1}p_{kj} \\lambda_{kj}, \\\\[1mm]\n",
    "\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "where $V_k := V_{k_{n-1}}\\otimes ... \\otimes V_{k_0}$ and $\\Lambda_k := \\Lambda_{k_{n-1}}\\otimes ... \\otimes \\Lambda_{k_0}$, such that: $\\hat{P_k}=V_k^\\dagger \\Lambda_k V_k.$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions\n",
    "\n",
    "Generally, cost functions are used to describe a problem's goal, and how well a trial state is performing with respect to the goal. This definition can be applied to examples across chemistry, machine learning, finance, optimization, etc.\n",
    "\n",
    "Let's use a simple example to illustrate this: finding the ground state of a system. Our goal is to minimize is the expectation value for the observable representing energy (*Hamiltonian* $\\hat{\\mathcal{H}}$):\n",
    "\n",
    "$$\n",
    "\\min_{\\vec\\theta} \\langle\\psi(\\vec\\theta)|\\hat{\\mathcal{H}}|\\psi(\\vec\\theta)\\rangle\n",
    "$$\n",
    "\n",
    "We can use the [_Estimator_ primitive](https://github.com/qiskit-community/prototype-zne/blob/main/docs/tutorials/0-estimator.ipynb) to evaluate the expectation value, and pass this value to an optimizer to minimize. If the optimization is successful, it will return a set of optimal parameter values $\\vec\\theta^*$, out of which we will be able to construct the _proposed solution state_ $|\\psi(\\vec\\theta^*)\\rangle$, and compute the observed expectation value as $C(\\vec\\theta^*)$.\n",
    "\n",
    "Notice how we will only be able to minimize the cost function for the limited set of states that we are considering. This leads us to two separate possiblities:\n",
    "\n",
    "- **Our ansatz does not define the solution state across the search space.** If this is the case, our optimizer will never find the solution, and we need to experiment with other ansatz that might able to represent our search space more accurately.\n",
    "- **Our optimizer is unable to find this valid solution**: Optimization can be globally defined and locally defined. We'll explore what this means in the later section.\n",
    "\n",
    "All in all, we will be performing a classical optimization loop but relaying the evaluation of the cost function to a quantum computer. From this perspective, one could think of the optimization as a purely classical endeavor where we call some _black-box quantum oracle_ each time the optimizer needs to evaluate the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_ibm_runtime import Session, QiskitRuntimeService\n",
    "\n",
    "service = QiskitRuntimeService(channel='ibm_quantum')\n",
    "\n",
    "def cost_function_vqe(theta):\n",
    "    observable = SparsePauliOp.from_list([\n",
    "        (\"XX\", 1),\n",
    "        (\"YY\", -3)\n",
    "    ])\n",
    "\n",
    "    reference_circuit = QuantumCircuit(2)\n",
    "    reference_circuit.x(0)\n",
    "    \n",
    "    variational_form = TwoLocal(2, rotation_blocks=['rz', 'ry'], entanglement_blocks='cx', entanglement='linear', reps=1)\n",
    "    ansatz = reference_circuit.compose(variational_form)\n",
    "    \n",
    "    with Session(service=service, backend=\"ibmq_qasm_simulator\") as session:\n",
    "        # Use estimator to get the expected values corresponding to each ansatz\n",
    "        estimator = Estimator()\n",
    "        job = estimator.run(ansatz, observable, theta)\n",
    "        values = job.result().values\n",
    "        session.close()\n",
    "        \n",
    "    return values\n",
    "\n",
    "theta_list = (2*np.pi*np.random.rand(1, 8)).tolist()\n",
    "cost_function_vqe(theta_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Strategy: Speed vs Accuracy\n",
    "\n",
    "As mentioned, we are using a noisy quantum computer as a *black-box oracle*, where noise can make the retrieved values non-deterministic, leading to random fluctuations which, in turn, will harm —or even completely prevent— convergence of certain optimizers to a proposed solution. This is a general problem that we must address as we incrementally progress towards quantum advantage:\n",
    "\n",
    "![Advantage](images/cost_function_path_to_quantum_advantage.png)\n",
    "\n",
    "We can use Qiskit Runtime Primitive's error suppression and error mitigation options to address noise and maximize the utility of today's quantum computers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "overhead": {
      "text": "Extra costs introduced by new techniques, relative to a base implementation.",
      "title": "Overhead"
     }
    }
   },
   "source": [
    "### Error Suppression\n",
    "\n",
    "[Error suppression](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-suppression.html) are techniques that optimize and transform your circuit at the point of compilation to minimize errors. This is the most basic error handling technique. Error suppression typically results in some classical pre-processing [overhead](gloss:overhead) to your overall runtime. This includes transpiling circuits to run on quantum hardware: \n",
    "\n",
    "- Expressing our circuit as the native gates available on a system\n",
    "- Mapping our virtual qubits to physical qubits\n",
    "- Adding SWAPs, based on connectivity requirements\n",
    "- Optimizing 1Q and 2Q gates\n",
    "- Adding dynamical decoupling to idle qubits to prevent the effects of decoherence.\n",
    "\n",
    "Primitives let you employ [error suppression techniques](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-suppression.html) by setting the `optimization_level` option and by choosing advanced transpilation options. In a later course, we'll dive deep into different circuit construction methods to improve your results, but we would recommend setting `optimization_level=3` for most cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "gloss": {
     "bias": {
      "text": "A systematic drift in the measured quantities, usually caused by errors.",
      "title": "Bias"
     }
    }
   },
   "source": [
    "### Error Mitigation\n",
    "\n",
    "[Error mitigation](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-mitigation.html) are techniques that allow users to mitigate circuit errors by modeling the device noise at the time of execution. This typically results in quantum pre-processing overhead related to model training, and classical post-processing overhead to mitigate errors in the raw results by using the generated model. \n",
    "\n",
    "Qiskit Runtime primitive's `resilience_level` option specifies how much resilience to build against errors. Higher levels generate more accurate results, at the expense of longer processing times due to quantum sampling overhead. Resilience levels can be used to configure the cost/accuracy trade-off when applying error mitigation to your primitive query. \n",
    "\n",
    "When implementing any error mitigation technique, we expect the [bias](gloss:bias) in our results to be reduced with respect to the previous, unmitigated, bias, in some cases even disappearing. However, this comes at a cost. As we reduce the bias in our estimated quantities, the statistical variability will increase (that is, variance), which we can account for by further increasing the number of shots per circuit in our sampling process. This will introduce overhead beyond that needed to reduce the bias, therefore it is not done by default. We can easily opt in to this behavior by adjusting the amount of shots per circuit in `options.executions.shots`, as shown in the example below.\n",
    "\n",
    "![Bias Variance Tradeoff](images/cost_function_bias_variance_trade_off.png)\n",
    "\n",
    "For this course, we'll explore these mitigation models at a high-level to illustrate the error mitigation that Qiskit Runtime primitives can perform without requiring full implementation details.\n",
    "\n",
    "\n",
    "#### Twirled readout error extinction (T-REx)\n",
    "\n",
    "Twirled readout error extinction (T-REx) uses a technique known as Pauli twirling to reduce the noise introduced during the process of quantum measurement. This technique assumes no specific form of noise, which makes it very general and effective.\n",
    "\n",
    "Overall workflow:\n",
    "\n",
    "1. Acquire data for the zero state with randomized bit flips (Pauli X before measurement)\n",
    "2. Acquire data for the desired (noisy) state with randomized bit flips (Pauli X before measurement)\n",
    "3. Compute the special function for each data set, and divide.\n",
    "\n",
    "![TRE-X](images/cost_function_trex_data_collection.png)\n",
    "\n",
    "We can set this with `options.resilience_level = 1`, demonstrated in the example below.\n",
    "\n",
    "### Zero noise extrapolation\n",
    "\n",
    "Zero noise extrapolation (ZNE) works by first amplifying the noise in the circuit that is preparing the desired quantum state, obtaining measurements for several different levels of noise, and using those measurements to infer the noiseless result. \n",
    "\n",
    "Overall workflow:\n",
    "\n",
    "1. Amplify circuit noise for several noise factors\n",
    "2. Run every noise amplified circuit\n",
    "3. Extrapolate back to the zero noise limit\n",
    "\n",
    "![ZNE](images/cost_function_zne_stages.png)\n",
    "\n",
    "We can set this with `options.resilience_level = 2`. We can optimize this further by exploring a variety of `noise_factors`, `noise_amplifiers`, and `extrapolators`, but this outside the scope of thise course. We encourage you to experiment with these [options as described here](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-mitigation.html#advanced-resilience-options).\n",
    "\n",
    "#### Probabilistic error cancellation\n",
    "\n",
    "Probabilistic error cancellation (PEC) samples for a collection of circuits that, on average mimics a noise inverting channel to cancel out the noise in the desired computation. This process is a bit like how noise-cancelling headphones work, and produces great results. However, it is not as general as other methods, and the sampling overhead is exponential.\n",
    "\n",
    "Overall workflow:\n",
    "\n",
    "![PEC](images/cost_function_pec_layers.png)\n",
    "\n",
    "Step 1: Pauli Twirling\n",
    "\n",
    "![PEC Twirling](images/cost_function_pec_pauli_twirling.png)\n",
    "\n",
    "Step 2: Repeat layer and learn the noise\n",
    "\n",
    "![PEC Learning](images/cost_function_pec_learn_layer.png)\n",
    "\n",
    "Step 3: Derive a fidelity (error for each noise channel)\n",
    "\n",
    "![PEC Fidelity](images/cost_function_pec_curve_fitting.png)\n",
    "\n",
    "Each method come with their own associated overhead: a trade-off between the number of quantum computations needed (time) and the accuracy of our results:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c}\n",
    "  \\text{Methods} & R=1 \\text{, T-REx} & R=2 \\text{, ZNE} & R=3 \\text{, PEC} \\\\[1mm]\n",
    "  \\hline\n",
    "  \\text{Assumptions} & \\text{None} & \\text{Ability to scale noise} & \\text{Full knowledge of noise} \\\\[1mm]\n",
    "  \\text{Qubit overhead} & 1 & 1 & 1 \\\\[1mm]\n",
    "  \\text{Sampling overhead} & 2 & N_{\\text{noise-factors}} & \\mathcal{O}(e^{\\lambda N_{layers}}) \\\\[1mm]\n",
    "  \\text{Bias} & 0 & \\mathcal{O}(\\lambda^{N_{\\text{noise-factors}}}) & 0 \\\\[1mm]\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Qiskit Runtime's mitigation and suppression options\n",
    "\n",
    "Here's how we calculate an expectation value, while using error mitigation and suppression. This happens multiple times across an optimization loop, but we've kept the example simple to demonstrate configuring error mitigation and suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter, QuantumCircuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "theta = Parameter('theta')\n",
    "\n",
    "qc = QuantumCircuit(2)\n",
    "qc.x(1)\n",
    "qc.h(0)\n",
    "qc.cp(theta,0,1)\n",
    "qc.h(0)\n",
    "ZZ = SparsePauliOp.from_list([(\"ZZ\", 1)])\n",
    "\n",
    "qc.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup phases\n",
    "import numpy as np\n",
    "\n",
    "phases = np.linspace(0, 2*np.pi, 50)\n",
    "\n",
    "# phases need to be expressed as a list of lists in order to work\n",
    "individual_phases = [[phase] for phase in phases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create noise model\n",
    "from qiskit.providers.fake_provider import FakeManila\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime import Options\n",
    "\n",
    "\n",
    "# Make a noise model\n",
    "fake_backend = FakeManila()\n",
    "noise_model = NoiseModel.from_backend(fake_backend)\n",
    "\n",
    "# Set options to include the noise model\n",
    "options = Options()\n",
    "options.simulator = {\n",
    "    \"noise_model\": noise_model,\n",
    "    \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "    \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "    \"seed_simulator\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "uses-hardware"
    ]
   },
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import Session, QiskitRuntimeService, Estimator\n",
    "\n",
    "service = QiskitRuntimeService(channel='ibm_quantum')\n",
    "\n",
    "noisy_exp_values = []\n",
    "exp_values_with_em_es = []\n",
    "\n",
    "with Session(service=service, backend=\"ibmq_qasm_simulator\") as session:\n",
    "    # generate noisy results\n",
    "    estimator = Estimator(options=options)\n",
    "    job = estimator.run(\n",
    "        circuits=[qc]*len(phases),\n",
    "        parameter_values=individual_phases,\n",
    "        observables=[ZZ]*len(phases),\n",
    "        shots=1000\n",
    "    )\n",
    "    result = job.result()\n",
    "    noisy_exp_values = result.values\n",
    "    \n",
    "    options.optimization_level = 2\n",
    "    options.resilience_level = 1\n",
    "\n",
    "    # leverage mitigation and suppression\n",
    "    estimator = Estimator(options=options)\n",
    "    job = estimator.run(\n",
    "        circuits=[qc]*len(phases),\n",
    "        parameter_values=individual_phases,\n",
    "        observables=[ZZ]*len(phases),\n",
    "        shots=1000\n",
    "    )\n",
    "    result = job.result()\n",
    "    exp_values_with_em_es = result.values\n",
    "\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(phases, noisy_exp_values, 'o', label='Noisy')\n",
    "plt.plot(phases, exp_values_with_em_es, 'o', label='Mitigation + Suppression')\n",
    "plt.plot(phases, 2*np.sin(phases/2)**2-1, label='Theory')\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Expectation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this lesson, you learned how to create a cost function:\n",
    "\n",
    "- Create a cost function\n",
    "- How to leverage [Qiskit Runtime primitives](https://qiskit.org/documentation/apidoc/primitives.html) to mitigate and suppression noise\n",
    "- How to define a measurement strategy to optimize speed vs accuracy\n",
    "  \n",
    "Here's our high-level variational workload:\n",
    "\n",
    "![Cost Function Circuit](images/cost_function_circuit.png)\n",
    "\n",
    "Our cost function runs during every iteration of the optimization loop. The next lesson will explore how the classical optimizer uses our cost function evaluation to select new parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
