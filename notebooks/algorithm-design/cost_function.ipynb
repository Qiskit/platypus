{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions\n",
    "\n",
    "During this lesson, we'll learn how to evaluate a *cost function*:\n",
    "\n",
    "- First, we'll learn about [Qiskit Runtime primitives](https://qiskit.org/documentation/apidoc/primitives.html)\n",
    "- Define a *cost function* $C(\\vec\\theta)$. This is a problem-specific function that defines the problem's goal for the optimizer to minimize (or maximize)\n",
    "- Defining a measurement strategy with the Qiskit Runtime primitives. We'll be addressing noise while also optimizing speed vs accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitives\n",
    "\n",
    "All physical systems, whether classical or quantum, can exist in different states. For example, a car on a road can have a certain mass, position, speed, or acceleration that characterize its state. Similarly, quantum systems can also have different configurations or states, but they differ from classical systems in how we deal with measurements and state evolution. This leads to unique properties such as *superposition* and *entanglement* that are exclusive to quantum mechanics. Just like we can describe a car's state using physical properties like speed or acceleration, we can also describe the state of a quantum system using *observables*, which are mathematical objects.\n",
    "\n",
    "In quantum mechanics, states are represented by normalized complex column vectors, or *kets* ($|\\psi\\rangle$), and observables are hermitian linear operators ($\\hat{H}=\\hat{H}^{\\dagger}$) that act on the kets. An eigenvector ($|\\lambda\\rangle$) of an observable is known as an *eigenstate*. Measuring an observable for one of its eigenstates ($|\\lambda\\rangle$) will give us the corresponding eigenvalue ($\\lambda$) as readout.\n",
    "\n",
    "\n",
    "If you're wondering how to measure a quantum system and what you can measure, Qiskit offers two primitives that can help:\n",
    "\n",
    "* `Sampler`: Given a quantum state $|\\psi\\rangle$, this primitive obtains the probability of each possible computational basis state.\n",
    "* `Estimator`: Given a quantum observable $\\hat{H}$ and a state $|\\psi\\rangle$, this primitive computes the expected value of $\\hat{H}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sampler primitive\n",
    "\n",
    "The `Sampler` primitive calculates the probability of obtaining each possible state $|k\\rangle$ from the computational basis, given a quantum circuit that prepares the state $|\\psi\\rangle$. It calculates\n",
    "\n",
    "$$\n",
    "p_k = |\\langle k | \\psi \\rangle|^2 \\quad \\forall k \\in \\mathbb{Z}_2^n \\equiv \\{0,1,\\cdots,2^n-1\\},\n",
    "$$ \n",
    "\n",
    "Where $n$ is the number of qubits, and $k$ the integer representation of any possible output binary string $\\{0,1\\}^n$ (i.e. integers base $2$).\n",
    "\n",
    "\n",
    "[Qiskit Runtime's](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/stubs/qiskit_ibm_runtime.Sampler.html) `Sampler` runs the circuit multiple times on a quantum device, performing measurements on each run, and reconstructing the probability distribution from the recovered bitstrings. The more runs (or *shots*) it performs, the more accurate the results will be, but this requires more time and quantum resources.\n",
    "\n",
    "\n",
    "However, since the number of possible outputs grows exponentially with the number of qubits $n$ (i.e. $2^n$), the number of shots will need to grow exponentially as well in order to capture a _dense_ probability distribution. Therefore, `Sampler` is only efficient for *sparse* probability distributions; where the target state $|\\psi\\rangle$ must be expressible as a linear combination of the computational basis states, with the number of terms growing at most polynomially with the number of qubits: \n",
    "\n",
    "$$\n",
    "|\\psi\\rangle = \\sum^{\\text{Poly}(n)}_k w_k |k\\rangle.\n",
    "$$\n",
    "\n",
    "\n",
    "The `Sampler` can also be configured to retrieve probabilities from a subsection of the circuit, representing a subset of the total possible states."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Estimator primitive\n",
    "\n",
    "\n",
    "The `Estimator` primitive calculates the expectation value of an observable $\\hat{H}$ for a quantum state $|\\psi\\rangle$; where the observable probabilities can be expressed as $p_\\lambda = |\\langle\\lambda|\\psi\\rangle|^2$, being $|\\lambda\\rangle$ the eigenstates of the observable $\\hat{H}$. The expectation value is then defined as the average of all possible outcomes $\\lambda$ (i.e. the eigenvalues of the observable) of a measurement of the state $|\\psi\\rangle$, weighted by the corresponding probabilities: \n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi := \\sum_\\lambda p_\\lambda \\lambda = \\langle \\psi | \\hat{H} | \\psi \\rangle\n",
    "$$\n",
    "\n",
    "\n",
    "However, calculating the expectation value of an observable is not always possible, as we often don't know its eigenbasis. [Qiskit Runtime's](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/stubs/qiskit_ibm_runtime.Estimator.html) `Estimator` uses a complex algebraic process to estimate the expectation value on a real quantum device by breaking down the observable into a combination of other observables whose eigenbasis we do know.\n",
    "\n",
    "In simpler terms, `Estimator` breaks down any observable that it doesn't know how to measure into simpler, measurable observables called Pauli operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any operator can be expressed as a combination of $4^n$ Pauli operators. \n",
    "\n",
    "$$\n",
    "\\hat{P}_k := \n",
    "\\sigma_{k_{n-1}}\\otimes \\cdots \\otimes \\sigma_{k_0} \\quad \n",
    "\\forall k \\in \\mathbb{Z}_4^n \\equiv \\{0,1,\\cdots,4^n-1\\}, \\\\\n",
    "$$ \n",
    "\n",
    "such that \n",
    "\n",
    "$$\n",
    "\\hat{H} = \\sum^{4^n-1}_{k=0} w_k \\hat{P}_k,\n",
    "$$\n",
    "\n",
    "where $n$ is the number of qubits, $k \\equiv k_{n-1} \\cdots k_0$ for $k_l \\in \\mathbb{Z}_4 \\equiv \\{0, 1, 2, 3\\}$ (i.e. integers base $4$), and $(\\sigma_0, \\sigma_1, \\sigma_2, \\sigma_3) := (I, X, Y, Z)$.\n",
    "\n",
    "After performing this decomposition, `Estimator` derives a new circuit $V_k|\\psi\\rangle$ for each observable $\\hat{P}_k$ (i.e. from the original circuit), to effectively *diagonalize* the Pauli observable in the computational basis and measure it. We can easily measure Pauli observables because we know $V_k$ ahead of time, which is not the case generally for other observables.\n",
    "\n",
    "For each $\\hat{P}_{k}$, the Estimator runs the corresponding circuit on a quantum device multiple times, measures the output state in the computational basis, and calculates the probability $p_{kj}$ of obtaining each possible output $j$. It then looks for the eigenvalue $\\lambda_{kj}$ of $P_k$ corresponding to each output $j$, multiplies by $w_k$, and adds all the results together to obtain the expected value of the observable $\\hat{H}$ for the given state $|\\psi\\rangle$.\n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi = \n",
    "\\sum_{k=0}^{4^n-1} w_k \\sum_{j=0}^{2^n-1}p_{kj} \\lambda_{kj},\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since calculating the expectation value of $4^n$ Paulis is impractical (i.e. exponentially growing), `Estimator` can only be efficient when a large amount of $w_k$ are zero (i.e. *sparse* Pauli decomposition instead of *dense*). Formally we say that, for this computation to be *efficiently solvable*, the number of non-zero terms has to grow at most polynomially with the number of qubits $n$: $\\hat{H} = \\sum^{\\text{Poly}(n)}_k w_k \\hat{P}_k.$\n",
    "\n",
    "The reader may notice the implicit assumption that probability sampling also needs to be efficient as explained for `Sampler`; which means\n",
    "\n",
    "$$\n",
    "\\langle\\hat{H}\\rangle_\\psi = \n",
    "\\sum_{k}^{\\text{Poly}(n)} w_k \\sum_{j}^{\\text{Poly}(n)}p_{kj} \\lambda_{kj}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided example to calculate expectation values\n",
    "\n",
    "Let's assume the single-qubit state $|+\\rangle := H|0\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$, and observable \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{H}\n",
    "& = \\begin{pmatrix} \n",
    "-1 & 2 \\\\\n",
    "2 & -1 \\\\\n",
    "\\end{pmatrix}\\\\[1mm]\n",
    "& = 2X - Z\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "with the following theoretical expectation value $\\langle\\hat{H}\\rangle_+ = \\langle+|\\hat{H}|+\\rangle = 2.$\n",
    "\n",
    "Since we do not know how to measure this observable, we cannot compute its expectation value directly, and we need to re-express it as $\\langle\\hat{H}\\rangle_+ = 2\\langle X \\rangle_+ - \\langle Z \\rangle_+ $. Which can be shown to evaluate to the same result by virtue of noting that $\\langle+|X|+\\rangle = 1$, and $\\langle+|Z|+\\rangle = 0$.\n",
    "\n",
    "Let see how to compute $\\langle X \\rangle_+$ and $\\langle Z \\rangle_+$ directly. Since $X$ and $Z$ do not commute (i.e. don't share the same eigenbasis), they cannot be measured simultaneously, therefore we need the auxiliary circuits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# The following code will work for any other initial single-qubit state and observable\n",
    "original_circuit = QuantumCircuit(1)\n",
    "original_circuit.h(0)\n",
    "\n",
    "H = SparsePauliOp([\"X\", \"Z\"], [2, -1])\n",
    "\n",
    "aux_circuits = []\n",
    "for pauli in H.paulis:\n",
    "    aux_circ = original_circuit.copy()\n",
    "    aux_circ.barrier()\n",
    "    if str(pauli) == \"X\":\n",
    "        aux_circ.h(0)\n",
    "    elif str(pauli) == \"Y\":\n",
    "        aux_circ.sdg(0)\n",
    "        aux_circ.h(0)\n",
    "    else:\n",
    "        aux_circ.i(0)\n",
    "    aux_circ.measure_all()\n",
    "    aux_circuits.append(aux_circ)\n",
    "\n",
    "\n",
    "print(\"Original circuit:\")\n",
    "display(original_circuit.draw(\"mpl\"))\n",
    "for (circuit, pauli) in zip(aux_circuits, H.paulis):\n",
    "    print(f\"Auxiliary circuit for {str(pauli)}\")\n",
    "    display(circuit.draw(\"mpl\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now carry out the computation manually using `Sampler` and check the results on `Estimator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import Sampler, Estimator\n",
    "from qiskit.circuit.library import IGate, ZGate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## SAMPLER\n",
    "sampler = Sampler()\n",
    "job = sampler.run(aux_circuits)\n",
    "probability_dists = job.result().quasi_dists\n",
    "\n",
    "expvals = []\n",
    "for dist, pauli in zip(probability_dists, H.paulis): \n",
    "    val = 0\n",
    "    if str(pauli) == \"I\":\n",
    "        Lambda = IGate().to_matrix().real\n",
    "    else:\n",
    "        Lambda = ZGate().to_matrix().real\n",
    "    val += Lambda[0][0]*dist.get(0, 0)\n",
    "    val += Lambda[1][1]*dist.get(1, 0)\n",
    "    expvals.append(val)\n",
    "\n",
    "\n",
    "print(\"Sampler results:\")\n",
    "for (pauli, expval) in zip(H.paulis, expvals):\n",
    "    print(f\"  >> Expected value of {str(pauli)}: {expval:.5f}\")\n",
    "\n",
    "total_expval = np.sum(H.coeffs*expvals).real\n",
    "print(f\"  >> Total expected value: {total_expval:.5f}\")\n",
    "\n",
    "\n",
    "## ESTIMATOR\n",
    "observables = [*H.paulis, H]  # Note: run for individual Paulis as well as full observable H\n",
    "\n",
    "estimator = Estimator()\n",
    "job = estimator.run([original_circuit]*len(observables), observables)\n",
    "estimator_expvals = job.result().values\n",
    "\n",
    "print(\"Estimator results:\")\n",
    "for (obs, expval) in zip(observables, estimator_expvals):\n",
    "    if obs is not H:\n",
    "        print(f\"  >> Expected value of {str(obs)}: {expval:.5f}\")\n",
    "    else:\n",
    "        print(f\"  >> Total expected value: {expval:.5f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical rigor (optional)\n",
    "\n",
    "Expressing $|\\psi\\rangle$ with respect to the basis of eigenstates of $\\hat{H}$, $|\\psi\\rangle = \\sum_\\lambda a_\\lambda |\\lambda\\rangle$, it follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle \\psi | \\hat{H} | \\psi \\rangle\n",
    "& = \\bigg(\\sum_{\\lambda'}a^*_{\\lambda'} \\langle \\lambda'|\\bigg) \\hat{H} \n",
    "  \\bigg(\\sum_{\\lambda} a_\\lambda | \\lambda\\rangle\\bigg)\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \n",
    "  \\langle \\lambda'|\\hat{H}| \\lambda\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \\lambda \n",
    "\\langle \\lambda'| \\lambda\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{\\lambda}\\sum_{\\lambda'} a^*_{\\lambda'}a_{\\lambda} \\lambda \n",
    "\\cdot \\delta_{\\lambda, \\lambda'}\\\\[1mm]\n",
    "\n",
    "& = \\sum_\\lambda |a_\\lambda|^2 \\lambda\\\\[1mm]\n",
    "\n",
    "& = \\sum_\\lambda p_\\lambda \\lambda\\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we do not know the eigenvalues or eigenstates of the target observable $\\hat{H}$, first we need to consider its diagonalization. Given that $\\hat{H}$ is Hermitian, there exists a unitary transformation $V$ such that $\\hat{H}=V^\\dagger \\Lambda V,$ where $\\Lambda$ is the diagonal eigenvalue matrix, so $\\langle j | \\Lambda | k \\rangle = 0$ if $j\\neq k$, and $\\langle j | \\Lambda | j \\rangle = \\lambda_j$.\n",
    "\n",
    "This implies that the expected value can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle\n",
    "& = \\langle\\psi|V^\\dagger \\Lambda V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\langle\\psi|V^\\dagger \\bigg(\\sum_{j=0}^{2^n-1} |j\\rangle \n",
    "\\langle j|\\bigg) \\Lambda \\bigg(\\sum_{k=0}^{2^n-1} |k\\rangle \\langle k|\\bigg) V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1} \\sum_{k=0}^{2^n-1}\\langle\\psi|V^\\dagger |j\\rangle \n",
    "\\langle j| \\Lambda  |k\\rangle \\langle k| V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1}\\langle\\psi|V^\\dagger |j\\rangle \n",
    "\\langle j| \\Lambda  |j\\rangle \\langle j| V|\\psi\\rangle\\\\[1mm]\n",
    "\n",
    "& = \\sum_{j=0}^{2^n-1}|\\langle j| V|\\psi\\rangle|^2 \\lambda_j\\\\[1mm]\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Given that if a system is in the state $|\\phi\\rangle = V |\\psi\\rangle$ the probability of measuring $| j\\rangle$ is $p_j = |\\langle j|\\phi \\rangle|^2$, the above expected value can be expressed as:\n",
    "\n",
    "$$\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle = \n",
    "\\sum_{j=0}^{2^n-1} p_j \\lambda_j.\n",
    "$$\n",
    "\n",
    "It is very important to note that the probabilities are taken from the state $V |\\psi\\rangle$ instead of $|\\psi\\rangle$. This is why the matrix $V$ is absolutely necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering how to obtain the matrix $V$ and the eigenvalues $\\Lambda$. If you already had the eigenvalues, then there would be no need to use a quantum computer since the goal of variational algorithms is to find these eigenvalues of $\\hat{H}$.\n",
    "\n",
    "Fortunately, there is a way around that: any $2^n \\times 2^n$ matrix can be written as a linear combination of $4^n$ tensor products of $n$ Pauli matrices and identities, all of which are both hermitian and unitary with known $V$ and $\\Lambda$. This is what Runtime's `Estimator` does internally by decomposing any [Operator](https://qiskit.org/documentation/stubs/qiskit.quantum_info.Operator.html) object into a [SparsePauliOp](https://qiskit.org/documentation/stubs/qiskit.quantum_info.SparsePauliOp.html).\n",
    "\n",
    "Here are the Operators that can be used:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|c|c|c}\n",
    "  \\text{Operator} & \\sigma & V & \\Lambda \\\\[1mm]\n",
    "  \\hline\n",
    "  I & \\sigma_0 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} & V_0 = I & \\Lambda_0 = I = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  X & \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} & V_1 = H =\\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix} & \\Lambda_1 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  Y & \\sigma_2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} & V_2 = HS^\\dagger  =\\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}\\cdot  \\begin{pmatrix} 1 & 0 \\\\ 0 & -i \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & -i \\\\ 1 & i \\end{pmatrix}\\quad & \\Lambda_2 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\\\[4mm]\n",
    "\n",
    "  Z & \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} & V_3 = I & \\Lambda_3 = \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's rewrite $\\hat{H}$ with respect to the Paulis and identities: \n",
    "\n",
    "$$\n",
    "\\hat{H} = \n",
    "\\sum_{k_{n-1}=0}^3...\n",
    "\\sum_{k_0=0}^3 w_{k_{n-1}...k_0} \n",
    "\\sigma_{k_{n-1}}\\otimes ... \\otimes \\sigma_{k_0} = \\sum_{k=0}^{4^n-1} w_k \\hat{P}_k,\n",
    "$$\n",
    "\n",
    "where $k = \\sum_{l=0}^{n-1} 4^l k_l \\equiv k_{n-1}...k_0$ for $k_{n-1},...,k_0\\in \\{0,1,2,3\\}$ (i.e. base $4$), and $\\hat{P}_{k} := \\sigma_{k_{n-1}}\\otimes ... \\otimes \\sigma_{k_0}$. Then,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\langle\\psi|\\hat{H}|\\psi\\rangle\n",
    "& = \\sum_{k=0}^{4^n-1} w_k \n",
    "\\sum_{j=0}^{2^n-1}|\\langle j| V_k|\\psi\\rangle|^2 \\langle j| \\Lambda_k |j\\rangle \\\\[1mm]\n",
    "\n",
    "& = \\sum_{k=0}^{4^n-1} w_k \\sum_{j=0}^{2^n-1}p_{kj} \\lambda_{kj}, \\\\[1mm]\n",
    "\n",
    "\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "where $V_k := V_{k_{n-1}}\\otimes ... \\otimes V_{k_0}$ and $\\Lambda_k := \\Lambda_{k_{n-1}}\\otimes ... \\otimes \\Lambda_{k_0}$, such that: $\\hat{P_k}=V_k^\\dagger \\Lambda_k V_k.$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Functions\n",
    "\n",
    "Generally, cost functions are used to describe a problem's goal, and how well a trial state is performing with respect to the goal. This definition can be applied to examples across chemistry, machine learning, finance, optimization, etc.\n",
    "\n",
    "Let's use a simple example to illustrate this: finding the ground state of a system. Our goal is to minimize is the expectation value for the observable representing energy (*Hamiltonian* $\\hat{\\mathcal{H}}$):\n",
    "\n",
    "$$\n",
    "\\min_{\\vec\\theta} \\langle\\psi(\\vec\\theta)|\\hat{\\mathcal{H}}|\\psi(\\vec\\theta)\\rangle\n",
    "$$\n",
    "\n",
    "We can use the [_Estimator_ primitive](https://github.com/qiskit-community/prototype-zne/blob/main/docs/tutorials/0-estimator.ipynb) to evaluate the expectation value, and pass this value to an optimizer to minimize. If the optimization is successful, it will return a set of optimal parameter values $\\vec\\theta^*$, out of which we will be able to construct the _proposed solution state_ $|\\psi(\\vec\\theta^*)\\rangle$, and compute the observed expectation value as $C(\\vec\\theta^*)$.\n",
    "\n",
    "Notice how we will only be able to minimize the cost function for the limited set of states that we are considering. This leads us to two separate possiblities:\n",
    "\n",
    "- **Our ansatz does not define the solution state across the search space.** If this is the case, our optimizer will never find the solution, and we need to experiment with other ansatz that might able to represent our search space more accurately.\n",
    "- **Our optimizer is unable to find this valid solution**: Optimization can be globally defined and locally defined. We'll explore what this means in the later section.\n",
    "\n",
    "All in all, we will be performing a classical optimization loop but relaying the evaluation of the cost function to a quantum computer. From this perspective, one could think of the optimization as a purely classical endeavor where we call some _black-box quantum oracle_ each time the optimizer needs to evaluate the cost function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Strategy: Speed vs Accuracy\n",
    "\n",
    "As mentioned, we using a noisy quantum computer as a *black-box oracle*, where noise can make the retrieved values non-deterministic, leading to random fluctuations which, in turn, will harm —or even completely prevent— convergence of certain optimizers to a proposed solution. This is a general problem that we must address as we incrementally progress towards quantum advantage:\n",
    "\n",
    "![Advantage](cost_function_path_to_quantum_advantage.png)\n",
    "\n",
    "We can use Qiskit Runtime Primitive's error suppression and error mitigation options to address noise:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Suppression\n",
    "\n",
    "[Error suppression](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-suppression.html) are techniques that optimize and transform your circuit at the point of compilation to minimize errors. This is the most basic error handling technique. Error suppression typically results in some classical pre-processing [overhead](gloss:overhead) to your overall runtime. Therefore, it is important to achieve a balance between perfecting your results and ensuring that your job completes in a reasonable amount of time.\n",
    "\n",
    "Primitives let you employ error suppression techniques by setting the `optimization_level` option and by choosing advanced transpilation options."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Mitigation\n",
    "\n",
    "[Error mitigation](https://qiskit.org/documentation/partners/qiskit_ibm_runtime/how_to/error-mitigation.html) are techniques that allow users to mitigate circuit errors by modeling the device noise at the time of execution. This typically results in quantum pre-processing overhead related to model training, and classical post-processing overhead to mitigate errors in the raw results by using the generated model. \n",
    "\n",
    "The `resilience_level` specifies how much resilience to build against errors. Higher levels generate more accurate results, at the expense of longer processing times due to quantum sampling overhead. Resilience levels can be used to configure the cost/accuracy trade-off when applying error mitigation to your primitive query. \n",
    "\n",
    "When implementing any error mitigation technique, we expect the [bias](gloss:bias) in our results to be reduced with respect to the previous, unmitigated, bias, in some cases even disappearing. However, this comes at a cost. As we reduce the bias in our estimated quantities, the statistical variability will increase (that is, variance), which we can account for by further increasing the number of shots per circuit in our sampling process. This will introduce overhead beyond that needed to reduce the bias, therefore it is not done by default. The user can easily opt in to this behavior by adjusting the amount of shots per circuit in `run_options`.\n",
    "\n",
    "![Bias Variance Tradeoff](cost_function_bias_variance_trade_off.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Qiskit Runtime's mitigation and suppression options\n",
    "\n",
    "Here's how we calculate an expectation value, while using error mitigation and suppression. This happens multiple times across an optimization loop, but we've kept the example simple to show error mitigation and suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import Parameter, QuantumCircuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "theta = Parameter('theta')\n",
    "\n",
    "qc = QuantumCircuit(2)\n",
    "qc.x(1)\n",
    "qc.h(0)\n",
    "qc.cp(theta,0,1)\n",
    "qc.h(0)\n",
    "ZZ = SparsePauliOp.from_list([(\"ZZ\", 1)])\n",
    "\n",
    "qc.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup phases\n",
    "import numpy as np\n",
    "\n",
    "phases = np.linspace(0, 2*np.pi, 50)\n",
    "\n",
    "# phases need to be expressed as a list of lists in order to work\n",
    "individual_phases = [[phase] for phase in phases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create noise model\n",
    "from qiskit.providers.fake_provider import FakeManila\n",
    "from qiskit_aer.noise import NoiseModel\n",
    "from qiskit_ibm_runtime import Options\n",
    "\n",
    "\n",
    "# Make a noise model\n",
    "fake_backend = FakeManila()\n",
    "noise_model = NoiseModel.from_backend(fake_backend)\n",
    "\n",
    "# Set options to include the noise model\n",
    "options = Options()\n",
    "options.simulator = {\n",
    "    \"noise_model\": noise_model,\n",
    "    \"basis_gates\": fake_backend.configuration().basis_gates,\n",
    "    \"coupling_map\": fake_backend.configuration().coupling_map,\n",
    "    \"seed_simulator\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "uses-hardware"
    ]
   },
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import Session, QiskitRuntimeService, Estimator\n",
    "\n",
    "service = QiskitRuntimeService()\n",
    "\n",
    "with Session(service=service, backend=\"ibmq_qasm_simulator\") as session:\n",
    "    # generate noisy results\n",
    "    estimator = Estimator(options=options)\n",
    "    job = estimator.run(\n",
    "        circuits=[qc]*len(phases),\n",
    "        parameter_values=individual_phases,\n",
    "        observables=[ZZ]*len(phases),\n",
    "        shots=1000\n",
    "    )\n",
    "    result = job.result()\n",
    "    noisy_exp_values = result.values\n",
    "    \n",
    "    options.optimization_level = 2\n",
    "    options.resilience_level = 1\n",
    "\n",
    "    # leverage mitigation and suppression\n",
    "    estimator = Estimator(options=options)\n",
    "    job = estimator.run(\n",
    "        circuits=[qc]*len(phases),\n",
    "        parameter_values=individual_phases,\n",
    "        observables=[ZZ]*len(phases),\n",
    "        shots=1000\n",
    "    )\n",
    "    result = job.result()\n",
    "    exp_values_with_em_es = result.values\n",
    "\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(phases, noisy_exp_values, 'o', label='Noisy')\n",
    "plt.plot(phases, exp_values_with_em_es, 'o', label='Mitigation + Suppression')\n",
    "plt.plot(phases, 2*np.sin(phases/2)**2-1, label='Theory')\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Expectation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this lesson, you learned how to create a cost function:\n",
    "\n",
    "- Create a cost function\n",
    "- How to leverage [Qiskit Runtime primitives](https://qiskit.org/documentation/apidoc/primitives.html) to mitigate and suppression noise\n",
    "- How to define a measurement strategy to optimize speed vs accuracy\n",
    "  \n",
    "Here's our high-level variational workload:\n",
    "\n",
    "\n",
    "\n",
    "Our cost function runs during every iteration of the optimization loop. The next lesson will explore how the classical optimizer uses our cost function evaluation to select new parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
